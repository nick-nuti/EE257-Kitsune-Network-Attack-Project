{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part g) Fine-Tuning\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "#reading ARP MitM dataset\n",
    "PATH = \"arp_mitm\"\n",
    "\n",
    "FILE = \"ARP MitM_dataset-002.csv\"\n",
    "L_FILE = \"ARP MitM_labels.csv\"\n",
    "\n",
    "#input data -> measured\n",
    "csv_path = os.path.join(PATH, FILE)\n",
    "dataset_filt = pd.read_csv(csv_path, header=None)  \n",
    "#dataset_filt = dataset.dropna()\n",
    "#display(dataset.head())\n",
    "#display(dataset.info())\n",
    "#display(dataset.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    x\n",
       "0           1  0.0\n",
       "1           2  0.0\n",
       "2           3  0.0\n",
       "3           4  0.0\n",
       "4           5  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   x           float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 38.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.252134e+06</td>\n",
       "      <td>4.573282e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.229198e+05</td>\n",
       "      <td>4.981759e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.260675e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.252134e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.878200e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x\n",
       "count  2.504267e+06  2.504267e+06\n",
       "mean   1.252134e+06  4.573282e-01\n",
       "std    7.229198e+05  4.981759e-01\n",
       "min    1.000000e+00  0.000000e+00\n",
       "25%    6.260675e+05  0.000000e+00\n",
       "50%    1.252134e+06  0.000000e+00\n",
       "75%    1.878200e+06  1.000000e+00\n",
       "max    2.504267e+06  1.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reading output data is the observation of malicous and none malicous \n",
    "csv_path_L = os.path.join(PATH, L_FILE)\n",
    "dataset_L_filt = pd.read_csv(csv_path_L, dtype={\"\": int, \"x\": 'float64'})  \n",
    "\n",
    "\n",
    "display(dataset_L_filt.head())\n",
    "display(dataset_L_filt.info())\n",
    "display(dataset_L_filt.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1358995\n",
       "1.0    1145272\n",
       "Name: x, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting how many malicous and non malicous was observed in the dataset\n",
    "#dataset_L_filt.drop('Unnamed: 0', axis=1)\n",
    "dataset_L_filt[\"x\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888993</td>\n",
       "      <td>0.555361</td>\n",
       "      <td>0.985682</td>\n",
       "      <td>0.916360</td>\n",
       "      <td>0.686321</td>\n",
       "      <td>0.930925</td>\n",
       "      <td>0.916909</td>\n",
       "      <td>0.832364</td>\n",
       "      <td>0.900150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.127438</td>\n",
       "      <td>0.894087</td>\n",
       "      <td>-0.452721</td>\n",
       "      <td>0.894087</td>\n",
       "      <td>-0.452881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268052</td>\n",
       "      <td>0.874687</td>\n",
       "      <td>0.981189</td>\n",
       "      <td>0.432338</td>\n",
       "      <td>0.824010</td>\n",
       "      <td>0.893352</td>\n",
       "      <td>0.657625</td>\n",
       "      <td>0.798113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.102821</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>-0.444215</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>-0.444355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555361</td>\n",
       "      <td>0.268052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640699</td>\n",
       "      <td>0.410116</td>\n",
       "      <td>0.977287</td>\n",
       "      <td>0.720824</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.875702</td>\n",
       "      <td>0.761625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.113905</td>\n",
       "      <td>0.750729</td>\n",
       "      <td>-0.319416</td>\n",
       "      <td>0.750729</td>\n",
       "      <td>-0.319555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985682</td>\n",
       "      <td>0.874687</td>\n",
       "      <td>0.640699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924874</td>\n",
       "      <td>0.760143</td>\n",
       "      <td>0.976825</td>\n",
       "      <td>0.954672</td>\n",
       "      <td>0.891553</td>\n",
       "      <td>0.952973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.136540</td>\n",
       "      <td>0.944589</td>\n",
       "      <td>-0.473812</td>\n",
       "      <td>0.944589</td>\n",
       "      <td>-0.473981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916360</td>\n",
       "      <td>0.981189</td>\n",
       "      <td>0.410116</td>\n",
       "      <td>0.924874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551961</td>\n",
       "      <td>0.897261</td>\n",
       "      <td>0.959641</td>\n",
       "      <td>0.748526</td>\n",
       "      <td>0.880278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.112048</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>-0.485679</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>-0.485831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.452721</td>\n",
       "      <td>-0.444215</td>\n",
       "      <td>-0.319416</td>\n",
       "      <td>-0.473812</td>\n",
       "      <td>-0.485679</td>\n",
       "      <td>-0.366071</td>\n",
       "      <td>-0.474741</td>\n",
       "      <td>-0.523971</td>\n",
       "      <td>-0.414893</td>\n",
       "      <td>-0.460251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.226496</td>\n",
       "      <td>-0.612351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.612351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.894087</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.750729</td>\n",
       "      <td>0.944589</td>\n",
       "      <td>0.885439</td>\n",
       "      <td>0.845051</td>\n",
       "      <td>0.968204</td>\n",
       "      <td>0.966637</td>\n",
       "      <td>0.939324</td>\n",
       "      <td>0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.086476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.612351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.612514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.452881</td>\n",
       "      <td>-0.444355</td>\n",
       "      <td>-0.319555</td>\n",
       "      <td>-0.473981</td>\n",
       "      <td>-0.485831</td>\n",
       "      <td>-0.366230</td>\n",
       "      <td>-0.474917</td>\n",
       "      <td>-0.524132</td>\n",
       "      <td>-0.415073</td>\n",
       "      <td>-0.460441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.226369</td>\n",
       "      <td>-0.612514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.612514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.888993  0.555361  0.985682  0.916360  0.686321  0.930925   \n",
       "1    0.888993  1.000000  0.268052  0.874687  0.981189  0.432338  0.824010   \n",
       "2    0.555361  0.268052  1.000000  0.640699  0.410116  0.977287  0.720824   \n",
       "3    0.985682  0.874687  0.640699  1.000000  0.924874  0.760143  0.976825   \n",
       "4    0.916360  0.981189  0.410116  0.924874  1.000000  0.551961  0.897261   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "110 -0.452721 -0.444215 -0.319416 -0.473812 -0.485679 -0.366071 -0.474741   \n",
       "111  0.894087  0.802862  0.750729  0.944589  0.885439  0.845051  0.968204   \n",
       "112 -0.452881 -0.444355 -0.319555 -0.473981 -0.485831 -0.366230 -0.474917   \n",
       "113       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "114       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          7         8         9    ...       105  106  107       108  \\\n",
       "0    0.916909  0.832364  0.900150  ... -0.217730  NaN  NaN -0.127438   \n",
       "1    0.893352  0.657625  0.798113  ... -0.313905  NaN  NaN -0.102821   \n",
       "2    0.625085  0.875702  0.761625  ...  0.035427  NaN  NaN -0.113905   \n",
       "3    0.954672  0.891553  0.952973  ... -0.216199  NaN  NaN -0.136540   \n",
       "4    0.959641  0.748526  0.880278  ... -0.324761  NaN  NaN -0.112048   \n",
       "..        ...       ...       ...  ...       ...  ...  ...       ...   \n",
       "110 -0.523971 -0.414893 -0.460251  ...  0.627931  NaN  NaN -0.226496   \n",
       "111  0.966637  0.939324  0.976353  ... -0.280132  NaN  NaN -0.086476   \n",
       "112 -0.524132 -0.415073 -0.460441  ...  0.627859  NaN  NaN -0.226369   \n",
       "113       NaN       NaN       NaN  ...       NaN  NaN  NaN       NaN   \n",
       "114       NaN       NaN       NaN  ...       NaN  NaN  NaN       NaN   \n",
       "\n",
       "          109       110       111       112  113  114  \n",
       "0    0.894087 -0.452721  0.894087 -0.452881  NaN  NaN  \n",
       "1    0.802862 -0.444215  0.802862 -0.444355  NaN  NaN  \n",
       "2    0.750729 -0.319416  0.750729 -0.319555  NaN  NaN  \n",
       "3    0.944589 -0.473812  0.944589 -0.473981  NaN  NaN  \n",
       "4    0.885439 -0.485679  0.885439 -0.485831  NaN  NaN  \n",
       "..        ...       ...       ...       ...  ...  ...  \n",
       "110 -0.612351  1.000000 -0.612351  1.000000  NaN  NaN  \n",
       "111  1.000000 -0.612351  1.000000 -0.612514  NaN  NaN  \n",
       "112 -0.612514  1.000000 -0.612514  1.000000  NaN  NaN  \n",
       "113       NaN       NaN       NaN       NaN  NaN  NaN  \n",
       "114       NaN       NaN       NaN       NaN  NaN  NaN  \n",
       "\n",
       "[115 rows x 115 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying to look at the coleration between feature but clearly this does not help much since we have wait too much data.\n",
    "#all the feature have some kind of coleration to one another as observe. This indicate that we cant fix one input while \n",
    "#changing the other inputs. \n",
    "correlation = dataset.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1426051 entries, 147800 to 2504266\n",
      "Columns: 115 entries, 0 to 114\n",
      "dtypes: float64(115)\n",
      "memory usage: 1.2 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1426051 entries, 147800 to 2504266\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   Unnamed: 0  1426051 non-null  int64  \n",
      " 1   x           1426051 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 32.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new with IQR outlier filtering:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Columns: 115 entries, 0 to 114\n",
      "dtypes: float64(115)\n",
      "memory usage: 2.1 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   x           float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 38.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Part g) Fine-Tuning\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import scipy.stats\n",
    "\n",
    "dataset = None\n",
    "dataset_L = None\n",
    "\n",
    "#extracing all rows that have values that abide by Zscore < 2 standard deviations from the mean\n",
    "\n",
    "z_score = np.abs(stats.zscore(dataset_filt))\n",
    "dataset = dataset_filt[(z_score < 2).all(axis=1)]\n",
    "dataset_L = dataset_L_filt[(z_score < 2).all(axis=1)]\n",
    "\n",
    "print(\"original dataset:\")\n",
    "display(dataset.info())\n",
    "display(dataset_L.info())\n",
    "print(\"new with IQR outlier filtering:\")\n",
    "display(dataset_filt.info())\n",
    "display(dataset_L_filt.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       1.00      1.00      1.00    167066\n",
      "    malicous       1.00      1.00      1.00    189446\n",
      "\n",
      "    accuracy                           1.00    356512\n",
      "   macro avg       1.00      1.00      1.00    356512\n",
      "weighted avg       1.00      1.00      1.00    356512\n",
      "\n",
      "0.9998204829009963\n",
      "\n",
      "TEST DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       1.00      1.00      1.00    502247\n",
      "    malicous       1.00      1.00      1.00    567292\n",
      "\n",
      "    accuracy                           1.00   1069539\n",
      "   macro avg       1.00      1.00      1.00   1069539\n",
      "weighted avg       1.00      1.00      1.00   1069539\n",
      "\n",
      "0.9998401180321616\n"
     ]
    }
   ],
   "source": [
    "# part h) accuracy scores\n",
    "\n",
    "#LDA classification model, the classification metric is also show in the result print out as the measurement of model accuratecy\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting the dataset for the cross validation test on unseen testing data. \n",
    "#splitting ratio is 3:1 for training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split( dataset, dataset_L, test_size=0.75, random_state=4)\n",
    "\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda_training = lda.fit(x_train,(y_train['x']==1)).predict(x_train)\n",
    "lda_testing = lda.fit(x_test,(y_test['x']==1)).predict(x_test)\n",
    "\n",
    "\n",
    "print(\"\\nTRAINING DATA:\")\n",
    "print(classification_report((y_train['x']==1), lda_training, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score((y_train['x']==1), lda_training))\n",
    "\n",
    "print(\"\\nTEST DATA:\")\n",
    "print(classification_report((y_test['x']==1), lda_testing, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score((y_test['x']==1), lda_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR MODEL WITH NO FEATURE SELECTION\n",
      "Training MSE =  0.0001795170990036801\n",
      "Testing MSE =  0.00015988196783847994\n"
     ]
    }
   ],
   "source": [
    "# part h) training mse and test mse\n",
    "\n",
    "print(\"FOR MODEL WITH NO FEATURE SELECTION\")\n",
    "print(\"Training MSE = \", mse(lda_training,y_train['x'].values))\n",
    "print(\"Testing MSE = \", mse(lda_testing,y_test['x'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's and 1's in y_train dataset:\n",
      "1.0    189446\n",
      "0.0    167066\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TRAINING SET: \n",
      " [[167063      3]\n",
      " [    61 189385]]\n",
      "\n",
      "Number of 0's and 1's in y_test dataset:\n",
      "1.0    567292\n",
      "0.0    502247\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TESTING SET: \n",
      " [[502241      6]\n",
      " [   157 567135]]\n"
     ]
    }
   ],
   "source": [
    "# part h) Confusion Matrices\n",
    "\n",
    "lda.fit(x_train,y_train['x'].values.ravel())\n",
    "\n",
    "y_tr_pred = lda.predict(x_train)\n",
    "y_pred = lda.predict(x_test)\n",
    "\n",
    "print(\"Number of 0's and 1's in y_train dataset:\")\n",
    "print(y_train['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TRAINING SET: \\n {}\".format(confusion_matrix(y_train['x'].values.ravel(), y_tr_pred)))\n",
    "\n",
    "print(\"\\nNumber of 0's and 1's in y_test dataset:\")\n",
    "print(y_test['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TESTING SET: \\n {}\".format(confusion_matrix(y_test['x'].values.ravel(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part h) ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lda_roc = lda.predict_proba(x_test)\n",
    "\n",
    "false_pos, true_pos, throwaway= roc_curve(y_test['x'].values.ravel(), lda_roc[:, 1])\n",
    "\n",
    "plt.plot(false_pos, true_pos, label='ROC Curve')\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.title(\"ROC Curve for LDA Classifier Model\\nWith no Feature Selection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
