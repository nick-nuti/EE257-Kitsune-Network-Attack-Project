{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.999505</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>1.999703</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.999901</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>1.999990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.998985</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>9.313226e-10</td>\n",
       "      <td>2.999391</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>2.999797</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>2.999980</td>\n",
       "      <td>...</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999998</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.998061</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>9.313226e-10</td>\n",
       "      <td>3.998836</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>3.999612</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>3.999961</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.999996</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1             2         3       4             5         6    \\\n",
       "0  1.000000  1294.0  0.000000e+00  1.000000  1294.0  0.000000e+00  1.000000   \n",
       "1  1.000000  1514.0  0.000000e+00  1.000000  1514.0  0.000000e+00  1.000000   \n",
       "2  1.999505  1294.0  6.984919e-10  1.999703  1294.0  2.328306e-10  1.999901   \n",
       "3  2.998985  1294.0  9.313226e-10  2.999391  1294.0  4.656613e-10  2.999797   \n",
       "4  3.998061  1294.0  9.313226e-10  3.998836  1294.0  2.328306e-10  3.999612   \n",
       "\n",
       "      7             8         9    ...           105  106  107       108  \\\n",
       "0  1294.0  0.000000e+00  1.000000  ...  0.000000e+00  0.0  0.0  1.000000   \n",
       "1  1514.0  0.000000e+00  1.000000  ...  0.000000e+00  0.0  0.0  1.000000   \n",
       "2  1294.0  6.984919e-10  1.999990  ...  0.000000e+00  0.0  0.0  1.999999   \n",
       "3  1294.0  6.984919e-10  2.999980  ...  6.984919e-10  0.0  0.0  2.999998   \n",
       "4  1294.0  6.984919e-10  3.999961  ...  2.328306e-10  0.0  0.0  3.999996   \n",
       "\n",
       "      109       110     111           112  113  114  \n",
       "0  1294.0  0.000000  1294.0  0.000000e+00  0.0  0.0  \n",
       "1  1514.0  0.000000  1514.0  0.000000e+00  0.0  0.0  \n",
       "2  1294.0  0.000000  1294.0  0.000000e+00  0.0  0.0  \n",
       "3  1294.0  0.000015  1294.0  2.328306e-10  0.0  0.0  \n",
       "4  1294.0  0.000000  1294.0  0.000000e+00  0.0  0.0  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Columns: 115 entries, 0 to 114\n",
      "dtypes: float64(115)\n",
      "memory usage: 2.1 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.161843e+02</td>\n",
       "      <td>1.263429e+03</td>\n",
       "      <td>1.629564e+05</td>\n",
       "      <td>5.206959e+02</td>\n",
       "      <td>1.263908e+03</td>\n",
       "      <td>1.624291e+05</td>\n",
       "      <td>1.542137e+03</td>\n",
       "      <td>1.264399e+03</td>\n",
       "      <td>1.618282e+05</td>\n",
       "      <td>1.508207e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.618792e+05</td>\n",
       "      <td>-2.279080e-03</td>\n",
       "      <td>-7.277519e-07</td>\n",
       "      <td>2.433348e+04</td>\n",
       "      <td>1.264685e+03</td>\n",
       "      <td>3.848150e+02</td>\n",
       "      <td>1.319794e+03</td>\n",
       "      <td>1.617353e+05</td>\n",
       "      <td>-2.131455e-03</td>\n",
       "      <td>-5.309278e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.261311e+02</td>\n",
       "      <td>2.731945e+02</td>\n",
       "      <td>4.387131e+04</td>\n",
       "      <td>2.018029e+02</td>\n",
       "      <td>2.730516e+02</td>\n",
       "      <td>4.250538e+04</td>\n",
       "      <td>5.917664e+02</td>\n",
       "      <td>2.729755e+02</td>\n",
       "      <td>4.140203e+04</td>\n",
       "      <td>5.965275e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.570896e+04</td>\n",
       "      <td>1.849400e+00</td>\n",
       "      <td>6.071145e-04</td>\n",
       "      <td>6.679195e+03</td>\n",
       "      <td>2.771983e+02</td>\n",
       "      <td>1.050558e+02</td>\n",
       "      <td>7.498082e+01</td>\n",
       "      <td>4.563698e+04</td>\n",
       "      <td>1.538249e+00</td>\n",
       "      <td>5.666412e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.464452e+03</td>\n",
       "      <td>-4.688243e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.329919e+02</td>\n",
       "      <td>-2.887023e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.893583e+02</td>\n",
       "      <td>1.302018e+03</td>\n",
       "      <td>1.490105e+05</td>\n",
       "      <td>3.071747e+02</td>\n",
       "      <td>1.301232e+03</td>\n",
       "      <td>1.466209e+05</td>\n",
       "      <td>8.890711e+02</td>\n",
       "      <td>1.297967e+03</td>\n",
       "      <td>1.435192e+05</td>\n",
       "      <td>8.741032e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.793071e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.347740e+04</td>\n",
       "      <td>1.335240e+03</td>\n",
       "      <td>4.248047e+02</td>\n",
       "      <td>1.335240e+03</td>\n",
       "      <td>1.804590e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.604483e+02</td>\n",
       "      <td>1.328082e+03</td>\n",
       "      <td>1.727128e+05</td>\n",
       "      <td>6.178137e+02</td>\n",
       "      <td>1.331693e+03</td>\n",
       "      <td>1.754399e+05</td>\n",
       "      <td>1.921768e+03</td>\n",
       "      <td>1.336063e+03</td>\n",
       "      <td>1.789780e+05</td>\n",
       "      <td>1.945002e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809940e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.763519e+04</td>\n",
       "      <td>1.340819e+03</td>\n",
       "      <td>4.254162e+02</td>\n",
       "      <td>1.340819e+03</td>\n",
       "      <td>1.809789e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.041041e+02</td>\n",
       "      <td>1.342751e+03</td>\n",
       "      <td>1.882200e+05</td>\n",
       "      <td>6.662270e+02</td>\n",
       "      <td>1.342305e+03</td>\n",
       "      <td>1.863478e+05</td>\n",
       "      <td>1.974742e+03</td>\n",
       "      <td>1.341165e+03</td>\n",
       "      <td>1.843493e+05</td>\n",
       "      <td>1.964070e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.821485e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.802381e+04</td>\n",
       "      <td>1.341263e+03</td>\n",
       "      <td>4.259399e+02</td>\n",
       "      <td>1.341263e+03</td>\n",
       "      <td>1.814248e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.365877e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.942291e+05</td>\n",
       "      <td>8.073135e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.948259e+05</td>\n",
       "      <td>2.124893e+03</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.953075e+05</td>\n",
       "      <td>1.983936e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.257562e+05</td>\n",
       "      <td>7.038125e+01</td>\n",
       "      <td>8.482200e-02</td>\n",
       "      <td>3.091260e+04</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>6.525000e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.257562e+05</td>\n",
       "      <td>3.335587e+02</td>\n",
       "      <td>1.560442e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   3.161843e+02  1.263429e+03  1.629564e+05  5.206959e+02  1.263908e+03   \n",
       "std    1.261311e+02  2.731945e+02  4.387131e+04  2.018029e+02  2.730516e+02   \n",
       "min    1.000000e+00  6.000000e+01  0.000000e+00  1.000000e+00  6.000000e+01   \n",
       "25%    1.893583e+02  1.302018e+03  1.490105e+05  3.071747e+02  1.301232e+03   \n",
       "50%    3.604483e+02  1.328082e+03  1.727128e+05  6.178137e+02  1.331693e+03   \n",
       "75%    4.041041e+02  1.342751e+03  1.882200e+05  6.662270e+02  1.342305e+03   \n",
       "max    5.365877e+02  1.514000e+03  4.942291e+05  8.073135e+02  1.514000e+03   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   1.624291e+05  1.542137e+03  1.264399e+03  1.618282e+05  1.508207e+04   \n",
       "std    4.250538e+04  5.917664e+02  2.729755e+02  4.140203e+04  5.965275e+03   \n",
       "min    0.000000e+00  1.000000e+00  6.000000e+01  0.000000e+00  1.000000e+00   \n",
       "25%    1.466209e+05  8.890711e+02  1.297967e+03  1.435192e+05  8.741032e+03   \n",
       "50%    1.754399e+05  1.921768e+03  1.336063e+03  1.789780e+05  1.945002e+04   \n",
       "75%    1.863478e+05  1.974742e+03  1.341165e+03  1.843493e+05  1.964070e+04   \n",
       "max    4.948259e+05  2.124893e+03  1.514000e+03  4.953075e+05  1.983936e+04   \n",
       "\n",
       "       ...           105           106           107           108  \\\n",
       "count  ...  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   ...  1.618792e+05 -2.279080e-03 -7.277519e-07  2.433348e+04   \n",
       "std    ...  4.570896e+04  1.849400e+00  6.071145e-04  6.679195e+03   \n",
       "min    ...  0.000000e+00 -1.464452e+03 -4.688243e-01  1.000000e+00   \n",
       "25%    ...  1.793071e+05  0.000000e+00  0.000000e+00  2.347740e+04   \n",
       "50%    ...  1.809940e+05  0.000000e+00  0.000000e+00  2.763519e+04   \n",
       "75%    ...  1.821485e+05  0.000000e+00  0.000000e+00  2.802381e+04   \n",
       "max    ...  4.257562e+05  7.038125e+01  8.482200e-02  3.091260e+04   \n",
       "\n",
       "                109           110           111           112           113  \\\n",
       "count  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   1.264685e+03  3.848150e+02  1.319794e+03  1.617353e+05 -2.131455e-03   \n",
       "std    2.771983e+02  1.050558e+02  7.498082e+01  4.563698e+04  1.538249e+00   \n",
       "min    6.000000e+01  0.000000e+00  6.000000e+01  0.000000e+00 -8.329919e+02   \n",
       "25%    1.335240e+03  4.248047e+02  1.335240e+03  1.804590e+05  0.000000e+00   \n",
       "50%    1.340819e+03  4.254162e+02  1.340819e+03  1.809789e+05  0.000000e+00   \n",
       "75%    1.341263e+03  4.259399e+02  1.341263e+03  1.814248e+05  0.000000e+00   \n",
       "max    1.514000e+03  6.525000e+02  1.514000e+03  4.257562e+05  3.335587e+02   \n",
       "\n",
       "                114  \n",
       "count  2.504267e+06  \n",
       "mean  -5.309278e-07  \n",
       "std    5.666412e-04  \n",
       "min   -2.887023e-01  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.560442e-01  \n",
       "\n",
       "[8 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part g) Fine-Tuning\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# gathering the dataset\n",
    "\n",
    "\n",
    "PATH = \"arp_mitm\"\n",
    "\n",
    "FILE = \"ARP MitM_dataset-002.csv\"\n",
    "L_FILE = \"ARP MitM_labels.csv\"\n",
    "\n",
    "csv_path = os.path.join(PATH, FILE)\n",
    "dataset = pd.read_csv(csv_path, header=None)  \n",
    "\n",
    "display(dataset.head())\n",
    "display(dataset.info())\n",
    "display(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    x\n",
       "0           1  0.0\n",
       "1           2  0.0\n",
       "2           3  0.0\n",
       "3           4  0.0\n",
       "4           5  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   x           float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 38.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.252134e+06</td>\n",
       "      <td>4.573282e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.229198e+05</td>\n",
       "      <td>4.981759e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.260675e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.252134e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.878200e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x\n",
       "count  2.504267e+06  2.504267e+06\n",
       "mean   1.252134e+06  4.573282e-01\n",
       "std    7.229198e+05  4.981759e-01\n",
       "min    1.000000e+00  0.000000e+00\n",
       "25%    6.260675e+05  0.000000e+00\n",
       "50%    1.252134e+06  0.000000e+00\n",
       "75%    1.878200e+06  1.000000e+00\n",
       "max    2.504267e+06  1.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gathering classified output data for dataset\n",
    "\n",
    "L_csv_path = os.path.join(PATH, L_FILE)\n",
    "dataset_L = pd.read_csv(L_csv_path, dtype={\"\": int, \"x\": 'float64'})  \n",
    "\n",
    "display(dataset_L.head())\n",
    "display(dataset_L.info())\n",
    "display(dataset_L.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TREES CLASSIFIER FEATURE SELECTION\n",
    "# gathering testing and training data\n",
    "\n",
    "feature_list_etc=[12, 13, 27, 28, 58, 63, 77, 78, 108, 109]\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(dataset.iloc[:,feature_list_etc], dataset_L.drop('Unnamed: 0', axis=1), random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, multi_class='ovr', n_jobs=11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part g) fine tuning\n",
    "\n",
    "# EXTRA TREES CLASSIFIER FEATURE SELECTION\n",
    "# running logistic regression and training the model using fit with the training data\n",
    "\n",
    "# MODIFIED \"C\" OR INVERSE REGULARIZATION STRENGTH\n",
    "\n",
    "logreg1 = LogisticRegression(multi_class='ovr', solver='lbfgs', n_jobs=11, C=10.0)\n",
    "logreg1.fit(x1_train, y1_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TREES CLASSIFIER FEATURE SELECTION\n",
    "# predicting the training and test data\n",
    "\n",
    "y1_tr_pred = logreg1.predict(x1_train)\n",
    "y1_pred = logreg1.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.97      0.93      0.95   1019393\n",
      "    malicous       0.92      0.96      0.94    858807\n",
      "\n",
      "    accuracy                           0.94   1878200\n",
      "   macro avg       0.94      0.95      0.94   1878200\n",
      "weighted avg       0.95      0.94      0.94   1878200\n",
      "\n",
      "0.9447838355872644\n",
      "\n",
      "TEST DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.97      0.93      0.95    339602\n",
      "    malicous       0.92      0.96      0.94    286465\n",
      "\n",
      "    accuracy                           0.94    626067\n",
      "   macro avg       0.94      0.95      0.94    626067\n",
      "weighted avg       0.95      0.94      0.94    626067\n",
      "\n",
      "0.9448717150081382\n"
     ]
    }
   ],
   "source": [
    "# EXTRA TREES CLASSIFIER FEATURE SELECTION\n",
    "# finding the classification reports and accuracy scores for the training and testing datasets\n",
    "\n",
    "print(\"\\nTRAINING DATA:\")\n",
    "print(classification_report(y1_train, y1_tr_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y1_train, y1_tr_pred))\n",
    "\n",
    "print(\"\\nTEST DATA:\")\n",
    "print(classification_report(y1_test, y1_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's and 1's in y_train dataset:\n",
      "0.0    1019393\n",
      "1.0     858807\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TRAINING SET: \n",
      " [[949744  69649]\n",
      " [ 34058 824749]]\n",
      "\n",
      "Number of 0's and 1's in y_test dataset:\n",
      "0.0    339602\n",
      "1.0    286465\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TESTING SET: \n",
      " [[316332  23270]\n",
      " [ 11244 275221]]\n"
     ]
    }
   ],
   "source": [
    "# EXTRA TREES CLASSIFIER FEATURE SELECTION\n",
    "# confusion matrices for training and testing set\n",
    "\n",
    "print(\"Number of 0's and 1's in y_train dataset:\")\n",
    "print(y1_train['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TRAINING SET: \\n {}\".format(confusion_matrix(y1_train, y1_tr_pred)))\n",
    "\n",
    "print(\"\\nNumber of 0's and 1's in y_test dataset:\")\n",
    "print(y1_test['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TESTING SET: \\n {}\".format(confusion_matrix(y1_test, y1_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT K BEST FEATURE SELECTION\n",
    "# gathering testing and training data\n",
    "\n",
    "feature_list_skb=[12, 13, 27, 28, 63, 56, 77, 88, 108, 101]\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(dataset.iloc[:,feature_list_skb], dataset_L.drop('Unnamed: 0', axis=1), random_state=2, stratify=dataset_L.drop('Unnamed: 0', axis=1), test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000.0, multi_class='ovr', n_jobs=11)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part g) fine tuning\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# running logistic regression and training the model using fit with the training data\n",
    "\n",
    "# MODIFIED \"C\" OR INVERSE REGULARIZATION STRENGTH\n",
    "\n",
    "logreg2 = LogisticRegression(multi_class='ovr', solver='lbfgs', n_jobs=11, C=10000000.0)\n",
    "\n",
    "logreg2.fit(x2_train, y2_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT K BEST FEATURE SELECTION\n",
    "# predicting the training and test data\n",
    "\n",
    "y2_tr_pred = logreg2.predict(x2_train)\n",
    "y2_pred = logreg2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE =  0.009442287680302332\n",
      "Testing MSE =  0.009296129647465847\n"
     ]
    }
   ],
   "source": [
    "# part h) training mse and test mse\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# finding training and testing mse for the predictions found in the previous lines of code\n",
    "\n",
    "print(\"Training MSE = \", mse(y2_tr_pred,y2_train))\n",
    "print(\"Testing MSE = \", mse(y2_pred,y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.99      0.99      0.99    679497\n",
      "    malicous       0.99      0.99      0.99    572636\n",
      "\n",
      "    accuracy                           0.99   1252133\n",
      "   macro avg       0.99      0.99      0.99   1252133\n",
      "weighted avg       0.99      0.99      0.99   1252133\n",
      "\n",
      "0.9905577123196977\n",
      "\n",
      "TEST DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.99      0.99      0.99    679498\n",
      "    malicous       0.99      0.99      0.99    572636\n",
      "\n",
      "    accuracy                           0.99   1252134\n",
      "   macro avg       0.99      0.99      0.99   1252134\n",
      "weighted avg       0.99      0.99      0.99   1252134\n",
      "\n",
      "0.9907038703525342\n"
     ]
    }
   ],
   "source": [
    "# part h) accuracy scores\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# finding the classification reports and accuracy scores for the training and testing datasets\n",
    "\n",
    "print(\"\\nTRAINING DATA:\")\n",
    "print(classification_report(y2_train, y2_tr_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y2_train, y2_tr_pred))\n",
    "\n",
    "print(\"\\nTEST DATA:\")\n",
    "print(classification_report(y2_test, y2_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's and 1's in y_train dataset:\n",
      "0.0    679497\n",
      "1.0    572636\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TRAINING SET: \n",
      " [[672012   7485]\n",
      " [  4338 568298]]\n",
      "\n",
      "Number of 0's and 1's in y_test dataset:\n",
      "0.0    679498\n",
      "1.0    572636\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TESTING SET: \n",
      " [[672050   7448]\n",
      " [  4192 568444]]\n"
     ]
    }
   ],
   "source": [
    "# part h) Confusion Matrices\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# confusion matrices for training and testing set\n",
    "\n",
    "print(\"Number of 0's and 1's in y_train dataset:\")\n",
    "print(y2_train['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TRAINING SET: \\n {}\".format(confusion_matrix(y2_train, y2_tr_pred)))\n",
    "\n",
    "print(\"\\nNumber of 0's and 1's in y_test dataset:\")\n",
    "print(y2_test['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TESTING SET: \\n {}\".format(confusion_matrix(y2_test, y2_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part h) ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logreg2_roc = logreg2.predict_proba(x2_test)\n",
    "\n",
    "false_pos, true_pos, throwaway= roc_curve(y2_test, logreg2_roc[:, 1])\n",
    "\n",
    "plt.plot(false_pos, true_pos, label='ROC Curve')\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.title(\"ROC Curve for Logistic Regression Model\\nUtilizing Select K Best Classifier Feature Selection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
